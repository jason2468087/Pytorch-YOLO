{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import natsort\n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochSize = 200\n",
    "batchSize = 2\n",
    "testSize = 12\n",
    "valSize = 12\n",
    "learningRate = 1e-4\n",
    "momentum = 0.5\n",
    "printInterval = 10\n",
    "classSize = 6\n",
    "classLabel = ['Nine','Ten','Jack','Queen','King','Ace']\n",
    "\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "torch.cuda.set_device(0)\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timers:\n",
    "    def __init__(self):\n",
    "        self.trainTime = 0\n",
    "        self.testTime = 0\n",
    "        self.valTime = 0\n",
    "        self.forwardTime = 0\n",
    "        self.backwardTime = 0\n",
    "        self.dataLoadTime = 0\n",
    "        self.convToBoxTime = 0\n",
    "        self.BoxToConvTime = 0\n",
    "        self.yoloLossTime = 0\n",
    "        self.yoloActTime = 0\n",
    "        self.noMaxSupTime = 0\n",
    "        self.printBoxTime = 0\n",
    "\n",
    "    def printTimelaps(self):\n",
    "        print(\"Train Time:\",int(self.trainTime)-int(self.valTime),\" Test Time:\",int(self.testTime),\" Val Time:\",int(self.valTime),\" Forward Time:\",int(self.forwardTime),\" Backward Time:\",int(self.backwardTime),\n",
    "             \"\\nData Load Time:\",int(self.dataLoadTime),\" Conv To Box Time:\",int(self.convToBoxTime),\" Box To Conv Time:\",int(self.BoxToConvTime),\n",
    "              \"\\nYolo Loss Time:\",int(self.yoloLossTime),\"Yolo Activation Time:\",int(self.yoloActTime),\"Non Max Suppress Time:\",int(self.noMaxSupTime),\"Print Box Time:\",int(self.printBoxTime))\n",
    "\n",
    "t = Timers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mish(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = x * (torch.tanh(torch.nn.functional.softplus(x)))\n",
    "        return x\n",
    "\n",
    "    \n",
    "class ConvMish(nn.Module):\n",
    "    def __init__(self,inChannel,outChannel,kernelSize,stride):\n",
    "        super(ConvMish,self).__init__()\n",
    "        \n",
    "        pad = (kernelSize - 1) // 2\n",
    "        \n",
    "        self.conv = nn.Conv2d(inChannel,outChannel,kernel_size=kernelSize, padding=pad, stride=stride)\n",
    "        self.bn = nn.BatchNorm2d(outChannel)\n",
    "        self.mish = Mish()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.mish(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    \n",
    "class ConvLeaky(nn.Module):\n",
    "    def __init__(self,inChannel,outChannel,kernelSize,stride):\n",
    "        super(ConvLeaky,self).__init__()\n",
    "        \n",
    "        pad = (kernelSize - 1) // 2\n",
    "        \n",
    "        self.conv = nn.Conv2d(inChannel,outChannel,kernel_size=kernelSize, padding=pad, stride=stride)\n",
    "        self.bn = nn.BatchNorm2d(outChannel)\n",
    "        self.leaky = nn.LeakyReLU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.leaky(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backbone Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self,channel,numBlock):\n",
    "        super(ResBlock,self).__init__()\n",
    "        \n",
    "        self.ConvMish1 = ConvMish(channel,channel,1,1)\n",
    "        self.ConvMish2 = ConvMish(channel,channel,3,1)\n",
    "        \n",
    "        self.moduleList = nn.ModuleList()\n",
    "        for i in range(numBlock):\n",
    "            singleResBlock = nn.ModuleList()\n",
    "            singleResBlock.append(ConvMish(channel,channel,1,1))\n",
    "            singleResBlock.append(ConvMish(channel,channel,3,1))\n",
    "            self.moduleList.append(singleResBlock)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = x\n",
    "        for res in self.moduleList:\n",
    "            temp = out\n",
    "            for layer in res:\n",
    "                temp = layer(temp)\n",
    "        \n",
    "            out = out+temp\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    \n",
    "class CSPBlock(nn.Module):\n",
    "    def __init__(self,inChannel,outChannel,numRes):\n",
    "        super(CSPBlock,self).__init__()\n",
    "        \n",
    "        self.convMish1 = ConvMish(inChannel,outChannel,3,2)\n",
    "        self.convMish2 = ConvMish(outChannel,inChannel,1,1)\n",
    "        self.convMish3 = ConvMish(outChannel,inChannel,1,1)\n",
    "        self.convMish4 = ConvMish(inChannel,inChannel,1,1)\n",
    "        self.convMish5 = ConvMish(outChannel,outChannel,1,1)\n",
    "        \n",
    "        self.res = ResBlock(inChannel,numRes)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        out = self.convMish1(x)\n",
    "        \n",
    "        out1 = self.convMish2(out)\n",
    "        \n",
    "        out2 = self.convMish3(out)\n",
    "        out2 = self.res(out2)\n",
    "        out2 = self.convMish4(out2)\n",
    "        \n",
    "        out = torch.cat([out1, out2], dim=1)\n",
    "        out = self.convMish5(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseNet,self).__init__()\n",
    "        \n",
    "        self.convMish = ConvMish(3,32,3,1)\n",
    "        self.csp1 = CSPBlock(32,64,1)\n",
    "        self.csp2 = CSPBlock(64,128,2)\n",
    "        self.csp3 = CSPBlock(128,256,8)\n",
    "        self.csp4 = CSPBlock(256,512,8)\n",
    "        self.csp5 = CSPBlock(512,1024,4)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        out = self.convMish(x)\n",
    "        out = self.csp1(out)\n",
    "        out = self.csp2(out)\n",
    "        out3 = self.csp3(out)\n",
    "        out4 = self.csp4(out3)\n",
    "        out5 = self.csp5(out4)\n",
    "        \n",
    "        return out3,out4,out5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neck Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SPP,self).__init__()\n",
    "        \n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size = 5,stride = 1, padding = 5//2)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size = 9, stride = 1, padding = 9//2)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size = 13, stride = 1, padding = 13//2)\n",
    "        \n",
    "        self.convLeaky1 = ConvLeaky(1024,512,1,1)\n",
    "        self.convLeaky2 = ConvLeaky(512,1024,3,1)\n",
    "        self.convLeaky3 = ConvLeaky(1024,512,1,1)\n",
    "        \n",
    "        self.convLeaky4 = ConvLeaky(2048,512,1,1)\n",
    "        self.convLeaky5 = ConvLeaky(512,1024,3,1)\n",
    "        self.convLeaky6 = ConvLeaky(1024,512,1,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        out = self.convLeaky1(x)\n",
    "        out = self.convLeaky2(out)\n",
    "        out = self.convLeaky3(out)\n",
    "        \n",
    "        p1 = self.maxpool1(out)\n",
    "        p2 = self.maxpool2(out)\n",
    "        p3 = self.maxpool3(out)      \n",
    "        out = torch.cat([p3, p2, p1, out], dim=1)\n",
    "        \n",
    "        out = self.convLeaky4(out)\n",
    "        out = self.convLeaky5(out)\n",
    "        out = self.convLeaky6(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    \n",
    "class UpSampling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UpSampling,self).__init__()\n",
    "    \n",
    "    def forward(self,x,targetSize):\n",
    "        \n",
    "        return F.interpolate(x,size=(targetSize[2], targetSize[3]),mode='nearest')   \n",
    "    \n",
    "    \n",
    "class YOLONeck(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(YOLONeck,self).__init__()\n",
    "    \n",
    "        self.spp = SPP()\n",
    "        \n",
    "        self.convLeaky1 = ConvLeaky(512, 256, 1, 1)\n",
    "        self.upSample1 = UpSampling()\n",
    "        self.convLeaky2 = ConvLeaky(512, 256, 1, 1)\n",
    "        \n",
    "        self.convLeaky3 = ConvLeaky(512, 256, 1, 1)\n",
    "        self.convLeaky4 = ConvLeaky(256, 512, 3, 1)\n",
    "        self.convLeaky5 = ConvLeaky(512, 256, 1, 1)\n",
    "        self.convLeaky6 = ConvLeaky(256, 512, 3, 1)\n",
    "        self.convLeaky7 = ConvLeaky(512, 256, 1, 1)\n",
    "        \n",
    "        self.convLeaky8 = ConvLeaky(256, 128, 1, 1)\n",
    "        self.upSample2 = UpSampling()\n",
    "        self.convLeaky9 = ConvLeaky(256, 128, 1, 1)\n",
    "        \n",
    "        self.convLeaky10 = ConvLeaky(256, 128, 1, 1)\n",
    "        self.convLeaky11 = ConvLeaky(128, 256, 3, 1)\n",
    "        self.convLeaky12 = ConvLeaky(256, 128, 1, 1)\n",
    "        self.convLeaky13 = ConvLeaky(128, 256, 3, 1)\n",
    "        self.convLeaky14 = ConvLeaky(256, 128, 1, 1)\n",
    "    \n",
    "    def forward(self, csp3, csp4,csp5):\n",
    "        \n",
    "        out1 = self.spp(csp5)\n",
    "        \n",
    "        out2a = self.convLeaky1(out1)\n",
    "        out2a = self.upSample1(out2a,csp4.size())\n",
    "        out2b = self.convLeaky2(csp4)\n",
    "        out2 = torch.cat([out2a, out2b], dim=1)\n",
    "        \n",
    "        out2 = self.convLeaky3(out2)\n",
    "        out2 = self.convLeaky4(out2)\n",
    "        out2 = self.convLeaky5(out2)\n",
    "        out2 = self.convLeaky6(out2)\n",
    "        out2 = self.convLeaky7(out2)\n",
    "        \n",
    "        out3a = self.convLeaky8(out2)\n",
    "        out3a = self.upSample2(out3a,csp3.size())\n",
    "        out3b = self.convLeaky9(csp3)\n",
    "        out3 = torch.cat([out3a, out3b], dim=1)\n",
    "        \n",
    "        out3 = self.convLeaky10(out3)\n",
    "        out3 = self.convLeaky11(out3)\n",
    "        out3 = self.convLeaky12(out3)\n",
    "        out3 = self.convLeaky13(out3)\n",
    "        out3 = self.convLeaky14(out3)\n",
    "        \n",
    "        return out1,out2,out3\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO Head Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class YOLOHead(nn.Module):\n",
    "    def __init__(self,outChannel,numAnchor):\n",
    "        super(YOLOHead,self).__init__()\n",
    "        \n",
    "        self.convLeaky1 = ConvLeaky(128, 256, 3, 1)\n",
    "        self.convOut1 = nn.Conv2d(256,outChannel,kernel_size=1)\n",
    "        \n",
    "        self.convLeaky2= ConvLeaky(128, 256, 3, 2)\n",
    "        \n",
    "        self.convLeaky3 = ConvLeaky(512, 256, 1, 1)\n",
    "        self.convLeaky4 = ConvLeaky(256, 512, 3, 1)\n",
    "        self.convLeaky5 = ConvLeaky(512, 256, 1, 1)\n",
    "        self.convLeaky6 = ConvLeaky(256, 512, 3, 1)\n",
    "        self.convLeaky7 = ConvLeaky(512, 256, 1, 1)\n",
    "        \n",
    "        self.convLeaky8 = ConvLeaky(256, 512, 3, 1)\n",
    "        self.convOut2 = nn.Conv2d(512,outChannel,kernel_size=1)\n",
    "        \n",
    "        self.convLeaky9 = ConvLeaky(256, 512, 3, 2)\n",
    "        \n",
    "        self.convLeaky10 = ConvLeaky(1024, 512, 1, 1)\n",
    "        self.convLeaky11 = ConvLeaky(512, 1024, 3, 1)\n",
    "        self.convLeaky12 = ConvLeaky(1024, 512, 1, 1)\n",
    "        self.convLeaky13 = ConvLeaky(512, 1024, 3, 1)\n",
    "        self.convLeaky14 = ConvLeaky(1024, 512, 1, 1)\n",
    "        \n",
    "        self.convLeaky15 = ConvLeaky(512, 1024, 3, 1)\n",
    "        self.convOut3 = nn.Conv2d(1024,outChannel,kernel_size=1)\n",
    "        \n",
    "    \n",
    "    def forward(self,x1,x2,x3):\n",
    "        \n",
    "        out1 = self.convLeaky1(x3)\n",
    "        out1 = self.convOut1(out1)\n",
    "        \n",
    "        temp1 = self.convLeaky2(x3)\n",
    "        temp1 = torch.cat([temp1, x2], dim=1)\n",
    "        \n",
    "        temp1 = self.convLeaky3(temp1)\n",
    "        temp1 = self.convLeaky4(temp1)\n",
    "        temp1 = self.convLeaky5(temp1)\n",
    "        temp1 = self.convLeaky6(temp1)\n",
    "        temp1 = self.convLeaky7(temp1)\n",
    "        \n",
    "        out2 = self.convLeaky8(temp1)\n",
    "        out2 = self.convOut2(out2)\n",
    "        \n",
    "        temp2 = self.convLeaky9(temp1)\n",
    "        temp2 = torch.cat([temp2, x1], dim=1)\n",
    "        \n",
    "        temp2 = self.convLeaky10(temp2)\n",
    "        temp2 = self.convLeaky11(temp2)\n",
    "        temp2 = self.convLeaky12(temp2)\n",
    "        temp2 = self.convLeaky13(temp2)\n",
    "        temp2 = self.convLeaky14(temp2)\n",
    "        \n",
    "        out3 = self.convLeaky15(temp2)\n",
    "        out3 = self.convOut3(out3)\n",
    "                                   \n",
    "        return out1,out2,out3\n",
    "    \n",
    "    \n",
    "class YOLONet(nn.Module):\n",
    "    def __init__(self,numClass,numAnchor):\n",
    "        super(YOLONet,self).__init__()\n",
    "    \n",
    "        outChannel = (4 + 1 + numClass) * numAnchor\n",
    "        \n",
    "        self.backbone = DenseNet()\n",
    "        self.neck = YOLONeck()\n",
    "        self.head = YOLOHead(outChannel,numAnchor)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        \n",
    "        out1,out2,out3 = self.backbone(x)\n",
    "        out1,out2,out3 = self.neck(out1,out2,out3)\n",
    "        out1,out2,out3 = self.head(out1,out2,out3)\n",
    "        \n",
    "        return out1,out2,out3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Anchor:\n",
    "    def __init__(self,anchorW,anchorH,hIdx,wIdx,sIdx,rIdx,cellW):\n",
    "        self.cellW = cellW\n",
    "        \n",
    "        self.x_ctr = cellW/2+wIdx*cellW\n",
    "        self.y_ctr = cellW/2+hIdx*cellW\n",
    "        \n",
    "        self.width = anchorW\n",
    "        self.height = anchorH\n",
    "        \n",
    "        self.wIdx = wIdx\n",
    "        self.hIdx = hIdx\n",
    "        self.sIdx = sIdx\n",
    "        self.rIdx = rIdx\n",
    "        \n",
    "        self.x_min = self.x_ctr-anchorW/2\n",
    "        self.y_min = self.y_ctr-anchorH/2\n",
    "        self.x_max = self.x_ctr+anchorW/2\n",
    "        self.y_max = self.y_ctr+anchorH/2\n",
    "        \n",
    "    def getBox(self):\n",
    "        return np.array([self.x_min , self.y_min , self.x_max , self.y_max])\n",
    "    \n",
    "    def printBox(self):\n",
    "        print(\"X min:\",self.x_min,\"Y min:\",self.y_min,\"X max:\",self.x_max,\"Y max:\",self.y_max)\n",
    "        \n",
    "class ObjBox:\n",
    "    def __init__(self,x_bias,y_bias,h_bias,w_bias,cls,conf,anchor):\n",
    "        \n",
    "        self.x_ctr = anchor.x_ctr+(x_bias-0.5)*anchor.cellW\n",
    "        self.y_ctr = anchor.y_ctr+(y_bias-0.5)*anchor.cellW\n",
    "        \n",
    "        self.width = anchor.cellW*w_bias\n",
    "        self.height = anchor.cellW*h_bias\n",
    "        \n",
    "        self.x_min = self.x_ctr-self.width/2\n",
    "        self.y_min = self.y_ctr-self.height/2\n",
    "        self.x_max = self.x_ctr+self.width/2\n",
    "        self.y_max = self.y_ctr+self.height/2\n",
    "        \n",
    "        self.cls = cls\n",
    "        self.conf = conf\n",
    "        \n",
    "    def getBox(self):\n",
    "        return np.array([self.x_min , self.y_min , self.x_max , self.y_max])\n",
    "    \n",
    "    def printBox(self):\n",
    "        print(\"X min:\",self.x_min,\"Y min:\",self.y_min,\"X max:\",self.x_max,\"Y max:\",self.y_max)\n",
    "        \n",
    "class YOLOInterface:\n",
    "    def __init__(self,outputSize):\n",
    "        self.anchorSize = [0.05,0.1,0.25]\n",
    "        self.anchorRatio = [0.66,1,1.66]\n",
    "        self.anchorNum = 6\n",
    "        \n",
    "        self.outputSize = outputSize\n",
    "        \n",
    "        self.anchorW = np.zeros((len(self.anchorSize),len(self.anchorRatio))) # 3x3\n",
    "        self.anchorH = np.zeros((len(self.anchorSize),len(self.anchorRatio))) # 3x3\n",
    "        self.gridCellWidth = [1.0/outputSize[0][2], 1.0/outputSize[1][2], 1.0/outputSize[2][2]]\n",
    "        \n",
    "        self.fittedAnchorArr = []\n",
    "\n",
    "        self.ObjectLoss = nn.BCEWithLogitsLoss(pos_weight = torch.tensor([200]), reduction='sum').cuda() #1970pos_weight = torch.tensor([1970]),\n",
    "        self.ClassLoss = nn.BCEWithLogitsLoss(pos_weight = torch.tensor([200]), reduction='sum').cuda() #11850pos_weight = torch.tensor([11850]),\n",
    "        \n",
    "        \n",
    "        for i in range(len(self.anchorSize)):\n",
    "            for j in range(len(self.anchorRatio)):\n",
    "                self.anchorW[i,j] = self.anchorSize[i]*self.anchorRatio[j]\n",
    "                self.anchorH[i,j] = self.anchorSize[i]/self.anchorRatio[j]\n",
    "            \n",
    "    def IOU(self,ach,obj):\n",
    "        # ~~~~ Calculate IOU ~~~~\n",
    "        iou = 0\n",
    "        \n",
    "        xA = max(ach[0], obj[0])\n",
    "        yA = max(ach[1], obj[1])\n",
    "        xB = min(ach[2], obj[2])\n",
    "        yB = min(ach[3], obj[3])\n",
    "        \n",
    "        interArea = max(0, xB - xA) * max(0, yB - yA)\n",
    "        \n",
    "        achArea = (ach[2] - ach[0]) * (ach[3] - ach[1])\n",
    "        objArea = (obj[2] - obj[0]) * (obj[3] - obj[1])\n",
    "        \n",
    "        iou = interArea / float(achArea + objArea - interArea)\n",
    "        return iou\n",
    "    \n",
    "    # ~~~ For all output mtx and mtx slices, obtain anchor details with box dimension bias then store anchor obj ~~~ #\n",
    "    def convOutputToBox(self,yoloAns1,yoloAns2,yoloAns3):\n",
    "        convToBoxStartTime = time.time()\n",
    "        objBoxArr = []\n",
    "        matchAnchorArr = []\n",
    "        yoloAnsArr = [yoloAns1,yoloAns2,yoloAns3]\n",
    "        maxArr = []\n",
    "        clsMaxArr = []\n",
    "        classDtbArr = np.array([0,0,0,0,0,0])\n",
    "        loopIdx = 0\n",
    "        confidenceLevel = 0.95\n",
    "        \n",
    "        for sIdx in range(len(self.anchorSize)): # in range of (3)\n",
    "            yoloAns = yoloAnsArr[sIdx]\n",
    "            \n",
    "            for rIdx in range(len(self.anchorRatio)): # in range of (3)\n",
    "                \n",
    "                sliceIdx = rIdx*(5+classSize)\n",
    "                \n",
    "                isObjMtx = yoloAns[sliceIdx,:,:] # The first slice of output of [5+class Num]\n",
    "                classMtx = yoloAns[sliceIdx+5:sliceIdx+11,:,:]\n",
    "                \n",
    "                objPosArr = np.where(isObjMtx > confidenceLevel)\n",
    "                objPosArr = np.array(objPosArr)\n",
    "                \n",
    "                maxArr.append(np.amax(np.array(isObjMtx)))\n",
    "                clsMaxArr.append(np.amax(np.array(classMtx)))\n",
    "                # --- objPosArr = [[All hIdx],[All wIdx]] , shape = [2,obj amount] ---\n",
    "                \n",
    "                for objIdx in range(objPosArr.shape[1]): # in range of (amount of object matched in current anchor ratio & size)\n",
    "                    hIdx = objPosArr[0][objIdx]\n",
    "                    wIdx = objPosArr[1][objIdx]\n",
    "\n",
    "                    # ~~~ Determin matched anchor ~~~ #\n",
    "                    fitAnchor = Anchor(self.anchorW[sIdx,rIdx],self.anchorH[sIdx,rIdx],hIdx,wIdx,sIdx,rIdx,self.gridCellWidth[sIdx])\n",
    "                    matchAnchorArr.append(fitAnchor)\n",
    "\n",
    "                    # ~~~ Determine four corner of object box ~~~ #\n",
    "                    sliceIdx = rIdx*(5+classSize)\n",
    "                    x_bias = yoloAns[sliceIdx+1,hIdx,wIdx]\n",
    "                    y_bias = yoloAns[sliceIdx+2,hIdx,wIdx]\n",
    "                    h_bias = yoloAns[sliceIdx+3,hIdx,wIdx]\n",
    "                    w_bias = yoloAns[sliceIdx+4,hIdx,wIdx]\n",
    "                    clsArr = np.array(yoloAns[sliceIdx+5:sliceIdx+11,hIdx,wIdx])\n",
    "                    cls = np.argmax(clsArr)\n",
    "                    objBoxArr.append(ObjBox(x_bias,y_bias,h_bias,w_bias,cls,isObjMtx[hIdx,wIdx],fitAnchor))\n",
    "                    \n",
    "                    classDtbArr = np.add(classDtbArr,clsArr)\n",
    "                    loopIdx = loopIdx+1\n",
    "        t.convToBoxTime += time.time()-convToBoxStartTime\n",
    "        \n",
    "        return matchAnchorArr,objBoxArr\n",
    "\n",
    "    # ~~~ Assign object to cloest anchor, calculate IOU between anchors and every object, store anchor with max IOU ~~~ #\n",
    "    def dataToYOLOConv(self,objBoxes):\n",
    "        # --- objBoxes shape = [objects amount,class amount + xy min max] ---\n",
    "        # --- outputSize = [CxHxW] ---\n",
    "        BoxToConvStartTime = time.time()\n",
    "        yoloAns1 = np.zeros((self.outputSize[0][0],self.outputSize[0][1],self.outputSize[0][2])) #[CxHxW]\n",
    "        yoloAns2 = np.zeros((self.outputSize[1][0],self.outputSize[1][1],self.outputSize[1][2])) #[CxHxW]\n",
    "        yoloAns3 = np.zeros((self.outputSize[2][0],self.outputSize[2][1],self.outputSize[2][2])) #[CxHxW]\n",
    "        \n",
    "        for objIdx in range(objBoxes.shape[0]): # in range of amount of object in image\n",
    "            maxIOU = 0\n",
    "            fittedAnchor = 0\n",
    "            obj_x_ctr = (objBoxes[objIdx,6]+objBoxes[objIdx,8])/2\n",
    "            obj_y_ctr = (objBoxes[objIdx,7]+objBoxes[objIdx,9])/2\n",
    "            obj_h = objBoxes[objIdx,9]-objBoxes[objIdx,7]\n",
    "            obj_w = objBoxes[objIdx,8]-objBoxes[objIdx,6]\n",
    "            \n",
    "            for sIdx in range(len(self.anchorSize)): # in range of (3)\n",
    "                gridCellWidth = self.gridCellWidth[sIdx]\n",
    "\n",
    "                hIdx = math.floor(obj_y_ctr/gridCellWidth)\n",
    "                wIdx = math.floor(obj_x_ctr/gridCellWidth)\n",
    "                \n",
    "                for rIdx in range(len(self.anchorRatio)): # in range of (3)\n",
    "\n",
    "                    currentAnchor = Anchor(self.anchorW[sIdx,rIdx],self.anchorH[sIdx,rIdx],hIdx,wIdx,sIdx,rIdx,gridCellWidth)\n",
    "\n",
    "                    iou = self.IOU(currentAnchor.getBox(),objBoxes[objIdx,6:10])\n",
    "                    \n",
    "                    if iou > maxIOU:\n",
    "                        maxIOU = iou\n",
    "                        fittedAnchor = currentAnchor\n",
    "            \n",
    "            # ~~~~ Change the yoloAns value ~~~~\n",
    "            if fittedAnchor == 0:\n",
    "                print(objBoxes)\n",
    "                \n",
    "            hIdx = fittedAnchor.hIdx\n",
    "            wIdx = fittedAnchor.wIdx\n",
    "            rIdx = fittedAnchor.rIdx\n",
    "            sIdx = fittedAnchor.sIdx\n",
    "            cIdx = rIdx*(5+classSize)            \n",
    "            gridCellWidth = self.gridCellWidth[sIdx]\n",
    "            \n",
    "            if sIdx == 0:\n",
    "                yoloAns1[cIdx,hIdx,wIdx] = 1.0\n",
    "                yoloAns1[cIdx+1,hIdx,wIdx] = (obj_x_ctr-gridCellWidth*wIdx)/gridCellWidth\n",
    "                yoloAns1[cIdx+2,hIdx,wIdx] = (obj_y_ctr-gridCellWidth*hIdx)/gridCellWidth\n",
    "                yoloAns1[cIdx+3,hIdx,wIdx] = obj_h/gridCellWidth\n",
    "                yoloAns1[cIdx+4,hIdx,wIdx] = obj_w/gridCellWidth\n",
    "                yoloAns1[cIdx+5:cIdx+11,hIdx,wIdx] = objBoxes[objIdx,0:6]\n",
    "            elif sIdx == 1:\n",
    "                yoloAns2[cIdx,hIdx,wIdx] = 1.0\n",
    "                yoloAns2[cIdx+1,hIdx,wIdx] = (obj_x_ctr-gridCellWidth*wIdx)/gridCellWidth\n",
    "                yoloAns2[cIdx+2,hIdx,wIdx] = (obj_y_ctr-gridCellWidth*hIdx)/gridCellWidth\n",
    "                yoloAns2[cIdx+3,hIdx,wIdx] = obj_h/gridCellWidth\n",
    "                yoloAns2[cIdx+4,hIdx,wIdx] = obj_w/gridCellWidth\n",
    "                yoloAns2[cIdx+5:cIdx+11,hIdx,wIdx] = objBoxes[objIdx,0:6]\n",
    "            elif sIdx == 2:\n",
    "                yoloAns3[cIdx,hIdx,wIdx] = 1.0\n",
    "                yoloAns3[cIdx+1,hIdx,wIdx] = (obj_x_ctr-gridCellWidth*wIdx)/gridCellWidth\n",
    "                yoloAns3[cIdx+2,hIdx,wIdx] = (obj_y_ctr-gridCellWidth*hIdx)/gridCellWidth\n",
    "                yoloAns3[cIdx+3,hIdx,wIdx] = obj_h/gridCellWidth\n",
    "                yoloAns3[cIdx+4,hIdx,wIdx] = obj_w/gridCellWidth\n",
    "                yoloAns3[cIdx+5:cIdx+11,hIdx,wIdx] = objBoxes[objIdx,0:6]\n",
    "            \n",
    "            self.fittedAnchorArr.append(fittedAnchor)\n",
    "            \n",
    "        t.BoxToConvTime += time.time()-BoxToConvStartTime\n",
    "        \n",
    "        return yoloAns1,yoloAns2,yoloAns3\n",
    "    \n",
    "    def yoloLoss(self,output1,output2,output3,yoloAns1,yoloAns2,yoloAns3):\n",
    "        # --- outputn shape = yoloAnsn shape = [B,C,H,W] ---\n",
    "        yoloLossStartTime = time.time()\n",
    "        obj_loss = 0\n",
    "        xy_loss = 0\n",
    "        wh_loss = 0\n",
    "        class_loss = 0\n",
    "        \n",
    "        outputArr = [output1,output2,output3]\n",
    "        yoloAnsArr = [yoloAns1,yoloAns2,yoloAns3]\n",
    "        \n",
    "        for sIdx in range(len(self.anchorSize)): # in range of output conv amount (3)\n",
    "            \n",
    "            output = outputArr[sIdx]\n",
    "            output_mask = torch.zeros(output.size()).to(device)\n",
    "            yoloAns = yoloAnsArr[sIdx].type('torch.cuda.FloatTensor')\n",
    "            \n",
    "            for rIdx in range(len(self.anchorRatio)): # in range of (3)\n",
    "                sliceIdx = rIdx*(5+classSize)\n",
    "                \n",
    "                # ~~~~ Split Convolution channel ~~~~\n",
    "                obj_ans = yoloAns[:,sliceIdx,:,:]\n",
    "                xy_ans = yoloAns[:,sliceIdx+1:sliceIdx+3,:,:]\n",
    "                wh_ans = yoloAns[:,sliceIdx+3:sliceIdx+5,:,:]\n",
    "                class_ans = yoloAns[:,sliceIdx+5:sliceIdx+11,:,:]\n",
    "                \n",
    "                # ~~~~ Define mask ~~~~\n",
    "                mask = obj_ans \n",
    "                xywh_mask = torch.zeros(output.size()[0],2,output.size()[2],output.size()[3]).to(device)\n",
    "                class_mask = torch.zeros(output.size()[0],classSize,output.size()[2],output.size()[3]).to(device)\n",
    "                xywh_mask[:,0,:,:] = mask\n",
    "                xywh_mask[:,1,:,:] = mask\n",
    "                for mIdx in range(classSize):\n",
    "                    class_mask[:,mIdx,:,:] = mask\n",
    "                \n",
    "                # ~~~~ Mask the Convlution output ~~~~\n",
    "                obj_output = output[:,sliceIdx,:,:]\n",
    "                xy_output = output[:,sliceIdx+1:sliceIdx+3,:,:]*xywh_mask\n",
    "                wh_output = output[:,sliceIdx+3:sliceIdx+5,:,:]*xywh_mask\n",
    "                class_output = output[:,sliceIdx+5:sliceIdx+11,:,:]#*class_mask\n",
    "                \n",
    "                # ~~~~ Calculate Loss ~~~~\n",
    "                obj_loss += self.ObjectLoss(obj_output,obj_ans)\n",
    "                xy_loss += F.mse_loss(xy_output,xy_ans, reduction='sum')*100\n",
    "                wh_loss += F.mse_loss(wh_output,wh_ans, reduction='sum')*1000\n",
    "                class_loss += self.ClassLoss(class_output,class_ans)\n",
    "        \n",
    "        loss = obj_loss + xy_loss + wh_loss + class_loss\n",
    "        lossArr = [obj_loss,xy_loss,wh_loss,class_loss]\n",
    "        \n",
    "        t.yoloLossTime += time.time() - yoloLossStartTime\n",
    "        return loss,lossArr\n",
    "    \n",
    "    def yoloActivation(self,output1,output2,output3):\n",
    "        yoloActStartTime = time.time()\n",
    "        outputArr = [output1,output2,output3]\n",
    "        \n",
    "        for sIdx in range(len(self.anchorSize)):\n",
    "            output = outputArr[sIdx]\n",
    "            \n",
    "            for rIdx in range(len(self.anchorRatio)):\n",
    "                sliceIdx = rIdx*(5+classSize)            \n",
    "                output[:,sliceIdx,:,:] = F.sigmoid(output[:,sliceIdx,:,:])\n",
    "                output[:,sliceIdx+5:sliceIdx+11,:,:] = F.sigmoid(output[:,sliceIdx+5:sliceIdx+11,:,:])\n",
    "        \n",
    "        t.yoloActTime += time.time()-yoloActStartTime\n",
    "\n",
    "        return outputArr[0],outputArr[1],outputArr[2]\n",
    "    \n",
    "    def nonMaxSuppresion(self,anchorArr,objBoxArr):\n",
    "        noMaxSupStartTime = time.time()\n",
    "        maxBoxArr = []\n",
    "        maxAnchorArr = []\n",
    "        isMaxArr = np.zeros(len(objBoxArr))\n",
    "        confidenceLevel = 0.5\n",
    "        itr = 0\n",
    "        \n",
    "        while len(objBoxArr) > 0:\n",
    "            \n",
    "            # ~~~~ Find max confidence and save it ~~~~          \n",
    "            maxIdx = 0\n",
    "            maxObj = objBoxArr[0]\n",
    "            maxAnc = anchorArr[0]\n",
    "            for i in range(len(objBoxArr)):\n",
    "                if objBoxArr[i].conf > maxObj.conf:\n",
    "                    maxObj = objBoxArr[i]\n",
    "                    maxAnc = anchorArr[i]\n",
    "                    maxIdx = i\n",
    "            maxBoxArr.append(maxObj)\n",
    "            maxAnchorArr.append(maxAnc)\n",
    "            \n",
    "            # ~~~~ Find overlapped box and record in array ~~~~\n",
    "            overlapIdxArr = []\n",
    "            for i in range(len(objBoxArr)):\n",
    "                if objBoxArr[i].cls == maxObj.cls and i != maxIdx and self.IOU(maxObj.getBox(),objBoxArr[i].getBox()) > confidenceLevel: #\n",
    "                    overlapIdxArr.append(i)\n",
    "            \n",
    "            # ~~~~ Delete overlapped box and also max confidence object from array ~~~~\n",
    "            arrLength = len(overlapIdxArr)\n",
    "            for i in range(len(overlapIdxArr)-1,-1,-1):\n",
    "                objBoxArr.remove(objBoxArr[overlapIdxArr[i]])\n",
    "                anchorArr.remove(anchorArr[overlapIdxArr[i]])\n",
    "\n",
    "            objBoxArr.remove(maxObj)\n",
    "            anchorArr.remove(maxAnc)\n",
    "            \n",
    "            itr = itr+1\n",
    "        \n",
    "        t.noMaxSupTime += time.time()-noMaxSupStartTime\n",
    "        return maxAnchorArr,maxBoxArr\n",
    "    \n",
    "    def printBox(self,imgIdx,image,anchorArr,objBoxArr,ansBoxArr = []):\n",
    "        printBoxStartTime = time.time()\n",
    "        ax = plt.subplot(4,3,imgIdx+1)\n",
    "        ax.imshow(np.transpose(image[imgIdx].cpu(), (1, 2, 0)))\n",
    "        clsCount = np.zeros(classSize)\n",
    "        ansCount = np.zeros(classSize)\n",
    "        classColour = ['red','orange','yellow','lime','blue','magenta']\n",
    "\n",
    "        for j in range(len(anchorArr)):\n",
    "            # ~~~~ Plot Anchor ~~~~\n",
    "            x_min = anchorArr[j].x_min*imgLength\n",
    "            y_min = anchorArr[j].y_min*imgLength\n",
    "            w = anchorArr[j].width*imgLength\n",
    "            h = anchorArr[j].height*imgLength\n",
    "            #ax.add_patch(patches.Rectangle((x_min,y_min),w,h,linewidth=1,edgecolor='r',facecolor='none'))\n",
    "            #plt.plot(anchorArr[j].x_ctr*imgLength, anchorArr[j].y_ctr*imgLength, marker='o', markersize=3, color=\"red\")\n",
    "\n",
    "            # ~~~~ Plot Object ~~~~\n",
    "            x_min = objBoxArr[j].x_min*imgLength\n",
    "            y_min = objBoxArr[j].y_min*imgLength\n",
    "            w = objBoxArr[j].width*imgLength\n",
    "            h = objBoxArr[j].height*imgLength\n",
    "            cls = objBoxArr[j].cls\n",
    "            ax.add_patch(patches.Rectangle((x_min,y_min),w,h,linewidth=1,edgecolor=classColour[cls],facecolor='none'))\n",
    "            #plt.plot(objBoxArr[j].x_ctr*imgLength, objBoxArr[j].y_ctr*imgLength, marker='o', markersize=3, color=\"blue\")\n",
    "\n",
    "            clsCount[cls] = clsCount[cls]+1\n",
    "\n",
    "        \n",
    "        for i in range(len(ansBoxArr)):\n",
    "            ans = ansBoxArr[i].cls\n",
    "            ansCount[ans] = ansCount[ans]+1\n",
    "            \n",
    "        ansCount = ansCount.astype(int)\n",
    "        clsCount = clsCount.astype(int)\n",
    "        \n",
    "        ax.title.set_text(\n",
    "            'Nine:'+str(clsCount[0])+'/'+str(ansCount[0])+' Ten:'+str(clsCount[1])+'/'+str(ansCount[1])\n",
    "            +' Jack:'+str(clsCount[2])+'/'+str(ansCount[2])+' Queen:'+str(clsCount[3])+'/'+str(ansCount[3])\n",
    "            +' King:'+str(clsCount[4])+'/'+str(ansCount[4])+' Ace:'+str(clsCount[5])+'/'+str(ansCount[5]))\n",
    "\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        t.printBoxTime += time.time()-printBoxStartTime\n",
    "        return 0\n",
    "    \n",
    "yoloInterface = YOLOInterface([[33,52,52],[33,26,26],[33,13,13]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "network = YOLONet(6,3).to(device)\n",
    "#network.load_state_dict(torch.load(\"C:\\\\Users\\\\jason\\\\OneDrive\\\\文件\\\\Python NN\\\\Pytorch Pet\\\\weights161120.pth\"))\n",
    "\n",
    "optimizer = optim.Adam(network.parameters(), weight_decay=0.001,lr=learningRate)\n",
    "scheduler = ReduceLROnPlateau(optimizer,verbose=True,patience=10,min_lr=1e-7,factor=0.1)\n",
    "\n",
    "print('Memory Usage:')\n",
    "print('Allocated:', torch.cuda.memory_allocated(0)/1024/1024, 'MB')\n",
    "print('Cached:   ', torch.cuda.memory_allocated(0)/1024/1024, 'MB')\n",
    "\n",
    "pytorch_total_params = sum(p.numel() for p in network.parameters())\n",
    "print(\"\\nTotal Parameters:\",pytorch_total_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numbers\n",
    "inputSize = 416\n",
    "    \n",
    "HLSAugumentation = transforms.ColorJitter(brightness=[0.5,1.2], contrast=[0.7,1.2], saturation=[0.5,1.5])\n",
    "\n",
    "initAugumentation = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((inputSize,inputSize))\n",
    "])\n",
    "\n",
    "def translation(img,output,size):\n",
    "    newImg = torch.ones([3,size,size])\n",
    "    newImg_ = torch.ones([3,size,size])\n",
    "    \n",
    "    w_bias = random.uniform(-0.3, 0.3)\n",
    "    h_bias = random.uniform(-0.3, 0.3)\n",
    "    \n",
    "    w_shift = abs(int(w_bias*size))\n",
    "    h_shift = abs(int(h_bias*size))\n",
    "    \n",
    "    if w_bias > 0:\n",
    "        newImg[:,:,w_shift:size] = img[:,:,0:(size-w_shift)]\n",
    "    elif w_bias < 0:\n",
    "        newImg[:,:,0:(size-w_shift)] = img[:,:,w_shift:size]\n",
    "        \n",
    "    if h_bias > 0:\n",
    "        newImg_[:,h_shift:size,:] = newImg[:,0:(size-h_shift),:]\n",
    "    elif h_bias < 0:\n",
    "        newImg_[:,0:(size-h_shift),:] = newImg[:,h_shift:size,:]\n",
    "    \n",
    "    deleteIdxArr = []\n",
    "    for objIdx in range(output.shape[0]):\n",
    "        output[objIdx,6] = max(output[objIdx,6] + w_bias,0)\n",
    "        output[objIdx,7] = max(output[objIdx,7] + h_bias,0)\n",
    "        output[objIdx,8] = min(output[objIdx,8] + w_bias,1)\n",
    "        output[objIdx,9] = min(output[objIdx,9] + h_bias,1)\n",
    "        \n",
    "        if (output[objIdx,6] >= 1) or (output[objIdx,8] <= 0) or (output[objIdx,7] >= 1) or (output[objIdx,9] <= 0):\n",
    "            deleteIdxArr.append(objIdx)\n",
    "            \n",
    "    for i in range(len(deleteIdxArr)-1,-1,-1):\n",
    "        output = np.delete(output, deleteIdxArr[i], axis=0)\n",
    "        \n",
    "    return newImg_,output\n",
    "\n",
    "def randomWhiteCover(img,size,amount = 1,s_range = [0.15,0.35],r_range = [0.7,1.5]):\n",
    "        \n",
    "    for i in range(amount):\n",
    "        if (random.uniform(0,1) > 0.5):\n",
    "            s = random.uniform(s_range[0], s_range[1])\n",
    "            r = random.uniform(r_range[0], r_range[1])\n",
    "            \n",
    "            w = s*r\n",
    "            h = s/r\n",
    "\n",
    "            x_ctr = random.uniform(0,1)\n",
    "            y_ctr = random.uniform(0,1)\n",
    "\n",
    "            x_min = int(max(0,x_ctr-w/2)*size)\n",
    "            y_min = int(max(0,y_ctr-h/2)*size)\n",
    "            x_max = int(min(1,x_ctr+w/2)*size)\n",
    "            y_max = int(min(1,y_ctr+h/2)*size)\n",
    "\n",
    "            img[:,y_min:y_max,x_min:x_max] = random.uniform(0.85,1)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = \"C://Users//jason//OneDrive//圖片//Machine Learning Data//Card Detection//\"\n",
    "trainDir = os.path.join(dataDir,'train//')\n",
    "valDir = os.path.join(dataDir,'val//')\n",
    "testDir = os.path.join(dataDir,'test//')\n",
    "\n",
    "trainLabelDir = os.path.join(dataDir,\"train_labels.csv\")\n",
    "testLabelDir = os.path.join(dataDir,'test_labels.csv')\n",
    "\n",
    "class CardDetectionDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, isTrain = False):\n",
    "        \n",
    "        self.data = []\n",
    "        self.root_dir = root_dir\n",
    "        #self.transform = transform\n",
    "        self.files = os.listdir(root_dir)\n",
    "        self.isTrain = isTrain\n",
    "        \n",
    "        with open(csv_file, newline='') as f:\n",
    "            reader = csv.reader(f)\n",
    "            self.data = list(reader)\n",
    "        \n",
    "        self.data = np.array(self.data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        dataLoadStartTime = time.time()\n",
    "        \n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        img_name = os.path.join(self.root_dir,self.files[idx])\n",
    "        image = Image.open(img_name)\n",
    "\n",
    "        result = np.array(np.where(self.data[:,0] == self.files[idx]))\n",
    "        labelArr = np.array(['nine','ten','jack','queen','king','ace'])\n",
    "        \n",
    "        output = np.empty((0,classSize+4), float)\n",
    "        \n",
    "        for i in range(result.size):\n",
    "            output = np.append(output, np.zeros((1,classSize+4)), axis=0)\n",
    "            \n",
    "            imageW = float(self.data[result[0,i],1])\n",
    "            imageH = float(self.data[result[0,i],2])\n",
    "            \n",
    "            output[i,6] = float(self.data[result[0,i],4])/imageW # x_min norm\n",
    "            output[i,7] = float(self.data[result[0,i],5])/imageH # y_min norm\n",
    "            output[i,8] = float(self.data[result[0,i],6])/imageW # x_max norm\n",
    "            output[i,9] = float(self.data[result[0,i],7])/imageH # y_max norm\n",
    "            \n",
    "            label = self.data[result[0,i],3]\n",
    "            classIdx = np.where(labelArr == label)\n",
    "            output[i,classIdx[0]] = 1.0\n",
    "        \n",
    "        #if self.transform:\n",
    "        image = initAugumentation(image)\n",
    "        if self.isTrain:\n",
    "            image,output = translation(image,output,inputSize)\n",
    "            image = randomWhiteCover(image,inputSize,amount = 3)\n",
    "            image = HLSAugumentation(image)\n",
    "        \n",
    "        output1,output2,output3 = yoloInterface.dataToYOLOConv(output)\n",
    "\n",
    "        t.dataLoadTime += time.time()-dataLoadStartTime\n",
    "        return image,output1,output2,output3\n",
    "    \n",
    "trainData = CardDetectionDataset(trainLabelDir,trainDir,isTrain=True)\n",
    "valData = CardDetectionDataset(testLabelDir,testDir)\n",
    "testData = CardDetectionDataset(testLabelDir,testDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLoader = torch.utils.data.DataLoader(trainData,batch_size = batchSize,shuffle = True)\n",
    "valLoader = torch.utils.data.DataLoader(valData,batch_size = valSize,shuffle = True)\n",
    "testLoader = torch.utils.data.DataLoader(testData,batch_size = testSize,shuffle = False)\n",
    "\n",
    "trainDataSize = len(trainLoader.dataset)\n",
    "valDataSize = len(valLoader.dataset)\n",
    "testDataSize = len(testLoader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.2f}\".format(x)},threshold=sys.maxsize)\n",
    "examples = enumerate(trainLoader)\n",
    "batch_idx, (example_data,output1,output2,output3) = next(examples)\n",
    "\n",
    "\n",
    "imgLength = inputSize\n",
    "fig = plt.figure(figsize=(18, 18))\n",
    "for i in range(2):\n",
    "    anchorArr,objBoxArr = yoloInterface.convOutputToBox(output1[i,:,:,:].cpu(),output2[i,:,:,:].cpu(),output3[i,:,:,:].cpu())\n",
    "    anchorArr,objBoxArr = yoloInterface.nonMaxSuppresion(anchorArr,objBoxArr)\n",
    "    yoloInterface.printBox(i,example_data,anchorArr,objBoxArr,objBoxArr)\n",
    "\n",
    "t.printTimelaps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainLossArr = []\n",
    "trainCounterArr = []\n",
    "valLossArr = []\n",
    "valCounterArr = []\n",
    "testLossArr = []\n",
    "testCounterArr = [(i+1)*len(trainLoader.dataset) for i in range(epochSize)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    trainStartTime = time.time()\n",
    "    \n",
    "    network.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    \n",
    "    currentImg = 0\n",
    "    totalImg = len(trainLoader.dataset)\n",
    "    \n",
    "    for idx,(data,label1,label2,label3) in enumerate(trainLoader):\n",
    "        forwardStartTime = time.time()\n",
    "        # Put data to GPU\n",
    "        data = data.to(device)\n",
    "        label1 = label1.to(device)\n",
    "        label2 = label2.to(device)\n",
    "        label3 = label3.to(device)\n",
    "        \n",
    "        # Computations\n",
    "        optimizer.zero_grad()\n",
    "        output1,output2,output3 = network(data)\n",
    "        t.forwardTime += time.time() -forwardStartTime\n",
    "        \n",
    "        loss,lossArr = yoloInterface.yoloLoss(output1,output2,output3,label1,label2,label3)\n",
    "        \n",
    "        backwardStartTime = time.time()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        t.backwardTime += time.time() - backwardStartTime\n",
    "        \n",
    "        # Calculate acc and loss\n",
    "        epoch_loss += loss/testDataSize\n",
    "        \n",
    "        # Print and record every n interval\n",
    "        if idx % printInterval == 0:\n",
    "            \n",
    "            # Print\n",
    "            currentImg = idx * len(data)\n",
    "            epochProgress = currentImg/totalImg\n",
    "            lossValue = loss.item()\n",
    "            \n",
    "            val_loss = val()\n",
    "            \n",
    "            if idx == 0:\n",
    "                print('Train Epoch: {} [{}/{} (0%)]'.format(epoch,idx, len(trainLoader.dataset)))\n",
    "            else:                \n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]  Loss: {:.4f} Val Loss: {:.4f}'.format(\n",
    "                    epoch,currentImg,totalImg,epochProgress*100 ,lossValue/data.size()[0],val_loss))\n",
    "            \n",
    "            # Record\n",
    "            trainLossArr.append(lossValue)\n",
    "            trainCounterArr.append(\n",
    "            (batch_idx*batchSize) + ((epoch-1)*len(trainLoader.dataset)))\n",
    "            \n",
    "            valLossArr.append(val_loss)\n",
    "            valCounterArr.append(\n",
    "            (batch_idx*batchSize) + ((epoch-1)*len(trainLoader.dataset)))\n",
    "       \n",
    "    # Final print\n",
    "    print('Train Epoch: {} [{}/{} ({:.0f}%)]  Loss: {:.4f}'.format(epoch,totalImg,totalImg,100 ,loss.item()/data.size()[0]))\n",
    "    \n",
    "    t.trainTime += time.time()-trainStartTime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test(itr):\n",
    "    testStartTime = time.time()\n",
    "    \n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    test_lossArr = np.zeros(4)\n",
    "    test_accuracy = 0\n",
    "    idx = 0\n",
    "    printInterval = 10\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data,label1,label2,label3 in testLoader:\n",
    "            idx = idx+1\n",
    "            forwardStartTime = time.time()\n",
    "            # Data to GPU and compute\n",
    "            data = data.to(device)\n",
    "            label1 = label1.to(device)\n",
    "            label2 = label2.to(device)\n",
    "            label3 = label3.to(device)\n",
    "            \n",
    "            output1,output2,output3 = network(data)\n",
    "            t.forwardTime += time.time() -forwardStartTime\n",
    "            \n",
    "            loss,lossArr = yoloInterface.yoloLoss(output1,output2,output3,label1,label2,label3)\n",
    "            lossArr = np.array([lossArr[0].item(),lossArr[1].item(),lossArr[2].item(),lossArr[3].item()])\n",
    "            \n",
    "            test_loss += loss/testDataSize\n",
    "            test_lossArr = np.add(lossArr/testDataSize,test_lossArr)\n",
    "            \n",
    "            if itr > 0 and itr%10 == 0:\n",
    "                imgLength = inputSize\n",
    "                output1,output2,output3 = yoloInterface.yoloActivation(output1,output2,output3)\n",
    "\n",
    "                printBoxStartTime = time.time()\n",
    "                fig = plt.figure(figsize=(18, 18))\n",
    "                t.printBoxTime += time.time()-printBoxStartTime\n",
    "                for i in range(data.size()[0]):\n",
    "                    anchorArr,objBoxArr = yoloInterface.convOutputToBox(output1[i,:,:,:].cpu(),output2[i,:,:,:].cpu(),output3[i,:,:,:].cpu())\n",
    "                    anchorArr,objBoxArr = yoloInterface.nonMaxSuppresion(anchorArr,objBoxArr)\n",
    "                    ansAchArr,ansBoxArr = yoloInterface.convOutputToBox(label1[i,:,:,:].cpu(),label2[i,:,:,:].cpu(),label3[i,:,:,:].cpu())\n",
    "\n",
    "                    yoloInterface.printBox(i,data.cpu(),anchorArr,objBoxArr,ansBoxArr)\n",
    "    if itr > 0 and itr%10 == 0:            \n",
    "        printBoxStartTime = time.time()\n",
    "        plt.show()\n",
    "        t.printBoxTime += time.time()-printBoxStartTime\n",
    "        \n",
    "    test_loss = test_loss.item()\n",
    "    testLossArr.append(test_loss)\n",
    "    print(\"Test Total Loss: {:.1f} | Object Loss: {:.1f}, XY Loss: {:.1f}, WH Loss: {:.1f}, Class Loss: {:.1f}\\n\".format(\n",
    "        test_loss,test_lossArr[0],test_lossArr[1],test_lossArr[2],test_lossArr[3]))\n",
    "    \n",
    "    t.testTime += time.time() -testStartTime\n",
    "    \n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def val():\n",
    "    valStartTime = time.time()\n",
    "    \n",
    "    network.eval()\n",
    "    val_loss = 0\n",
    "    val_accuracy = 0\n",
    "    idx = 0\n",
    "    with torch.no_grad():\n",
    "        for data,label1,label2,label3 in valLoader:\n",
    "            \n",
    "            forwardStartTime = time.time()\n",
    "            data = data.to(device)\n",
    "            label1 = label1.to(device)\n",
    "            label2 = label2.to(device)\n",
    "            label3 = label3.to(device)\n",
    "            output1,output2,output3 = network(data)\n",
    "            t.forwardTime += time.time() -forwardStartTime\n",
    "            \n",
    "            loss, lossArr = yoloInterface.yoloLoss(output1,output2,output3,label1,label2,label3)\n",
    "            val_loss += loss/data.size()[0]\n",
    "            \n",
    "            break\n",
    "            \n",
    "    network.train()\n",
    "    val_loss = val_loss.item()\n",
    "    t.valTime += time.time()-valStartTime\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anaylse():\n",
    "    \n",
    "    network.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data,label1,label2,label3 in trainLoader:\n",
    "            \n",
    "            # Data to GPU and compute\n",
    "            data = data.to(device)\n",
    "            label1 = label1.to(device)\n",
    "            label2 = label2.to(device)\n",
    "            label3 = label3.to(device)\n",
    "            \n",
    "            output1,output2,output3 = network(data)\n",
    "            \n",
    "            loss,lossArr = yoloInterface.yoloLoss(output1,output2,output3,label1,label2,label3)\n",
    "            lossArr = np.array([lossArr[0].item(),lossArr[1].item(),lossArr[2].item(),lossArr[3].item()])\n",
    "            \n",
    "            output1,output2,output3 = yoloInterface.yoloActivation(output1,output2,output3)\n",
    "            \n",
    "            for imgIdx in range(data.size()[0]):\n",
    "                outputArr = [output1,output2,output3]\n",
    "                \n",
    "                fig = plt.figure(figsize=(18, 18))\n",
    "                pltIdx = 1\n",
    "                ax = plt.subplot(4,4,pltIdx)\n",
    "                ax.imshow(np.transpose(data[imgIdx].cpu(), (1, 2, 0)))\n",
    "                pltIdx += 1\n",
    "                \n",
    "                output = outputArr[2]\n",
    "                \n",
    "                outPlot = torch.zeros(7,13,13)\n",
    "\n",
    "                for rIdx in range(3):\n",
    "                    sliceIdx = rIdx*(5+classSize)\n",
    "                    \n",
    "                    outPlot[0,:,:] += output[imgIdx,sliceIdx,:,:]\n",
    "                    outPlot[1,:,:] += output[imgIdx,sliceIdx+5,:,:]\n",
    "                    outPlot[2,:,:] += output[imgIdx,sliceIdx+6,:,:]\n",
    "                    outPlot[3,:,:] += output[imgIdx,sliceIdx+7,:,:]\n",
    "                    outPlot[4,:,:] += output[imgIdx,sliceIdx+8,:,:]\n",
    "                    outPlot[5,:,:] += output[imgIdx,sliceIdx+9,:,:]\n",
    "                    outPlot[6,:,:] += output[imgIdx,sliceIdx+10,:,:]\n",
    "                    \n",
    "                for cIdx in range(outPlot.size()[0]):\n",
    "                    ax = plt.subplot(4,4,pltIdx)\n",
    "                    ax.imshow(outPlot[cIdx,:,:].cpu())\n",
    "                    pltIdx += 1\n",
    "                \n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wDecayStage = 0\n",
    "minLoss = 1000000\n",
    "\n",
    "for epoch in range(1,epochSize+1):\n",
    "    print(\"Epoch \",epoch)\n",
    "    startEpochTime = time.time()\n",
    "    train(epoch)\n",
    "    \n",
    "    loss = test(epoch)\n",
    "    scheduler.step(loss)\n",
    "    t.printTimelaps()\n",
    "    \n",
    "    if loss < minLoss:\n",
    "        minLoss = loss\n",
    "        torch.save(network.state_dict(), \"C:\\\\Users\\\\jason\\\\OneDrive\\\\文件\\\\Python NN\\\\Pytorch YOLO\\\\weight201221.pth\")\n",
    "        print(\"Model Saved\")\n",
    "    \n",
    "    if epoch == 100:\n",
    "        for param_gp in optimizer.param_groups:\n",
    "            param_gp['weight_decay'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Training Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bufferSize = 10\n",
    "\n",
    "trainCounterArr = []\n",
    "for i in range(len(trainLossArr)-bufferSize):\n",
    "    trainCounterArr.append(i)\n",
    "\n",
    "trainLossArr_ = []\n",
    "valLossArr_ = []\n",
    "\n",
    "for i in range(len(trainLossArr)-bufferSize):\n",
    "    trainLossArr_.append(np.average(trainLossArr[i:i+bufferSize]))\n",
    "    valLossArr_.append(np.average(valLossArr[i:i+bufferSize]))\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(trainCounterArr, trainLossArr_, color='blue')\n",
    "plt.plot(trainCounterArr, valLossArr_, color='red')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Saved Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "network.load_state_dict(torch.load(\"C:\\\\Users\\\\jason\\\\OneDrive\\\\文件\\\\Python NN\\\\Pytorch YOLO\\\\weight201220_analyse.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss = test(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "anaylse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = torch.ones(2, 13, 13, 11).cuda()\n",
    "for b in range(2):\n",
    "    for c in range(13):\n",
    "        for i in range(13):\n",
    "            for j in range(11):\n",
    "                output[b,c,i,j] = random.uniform(0, 1)\n",
    "pred = output[..., :4].clone()\n",
    "\n",
    "obj_mask = torch.ones(2, 3, 13, 13).cuda()\n",
    "\n",
    "predLen = pred[0].view(-1, 4).size()[0]\n",
    "ansLen = 5\n",
    "print(pred[b].view(-1, 4).size())\n",
    "pred_ious = torch.ones(predLen,ansLen).cuda()\n",
    "for i in range(predLen):\n",
    "    for j in range(ansLen):\n",
    "        pred_ious[i,j] = random.uniform(0, 1)\n",
    "print(\"Predict IOU:\",pred_ious)\n",
    "\n",
    "pred_best_iou, _ = pred_ious.max(dim=1)\n",
    "print(\"Predict IOU Max:\",pred_best_iou)\n",
    "\n",
    "pred_best_iou = (pred_best_iou > 0.9)\n",
    "print(\"Predict IOU Threshold:\",pred_best_iou)\n",
    "\n",
    "print(pred.size())\n",
    "pred_best_iou = pred_best_iou.view(pred[0].shape[:3])#pred[b].shape[:3]\n",
    "# set mask to zero (ignore) if pred matches truth\n",
    "obj_mask[0] = ~ pred_best_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
